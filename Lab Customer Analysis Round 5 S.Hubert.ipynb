{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "934ae21a",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Round 5\n",
    "\n",
    "For this lab, we still keep using the `marketing_customer_analysis.csv` file that you can find in the `files_for_lab` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64392f33",
   "metadata": {},
   "source": [
    "### 1. Get the data\n",
    "\n",
    "We are using the `marketing_customer_analysis.csv` file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea143d",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Dealing with the data\n",
    "\n",
    "Already done in the round 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b5d0e",
   "metadata": {},
   "source": [
    "### 3. Explore the data\n",
    "\n",
    "Some datasets have values that are missing, invalid, or otherwise difficult for an algorithm to process. If data is missing, the algorithm canâ€™t use it. If data is invalid, the algorithm produces less accurate or even misleading outcomes. Some datasets are relatively clean but need to be shaped (e.g., aggregated or pivoted) and many datasets are just lacking useful business context (e.g., poorly defined ID values), hence the need for feature enrichment. Good data preparation produces clean and well-curated data which leads to more practical, accurate model outcomes.\n",
    "\n",
    "\n",
    "   **3.1.- Determine the problems**\n",
    "    \n",
    "   **3.2.- Data cleaning** Cleaning the data is very important as the model learning from that data only, so if we feed inconsistent, appropriate data to model it will return garbage only, so it is required to make sure that the data does not contains any unseen problem.\n",
    "     \n",
    "       - Feature and Target Variables\n",
    "       - Data Types\n",
    "       - Missing data, check null values\n",
    "       - Outliers\n",
    "       - Duplicate data\n",
    "        \n",
    "   **3.3.- Feature selection** (Which variables are important to answer our questions?)\n",
    "    \n",
    "   **3.4.- Data transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22525dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906810c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44f9c3",
   "metadata": {},
   "source": [
    "### 4. Processing Data\n",
    "\n",
    "(_Further processing..._)\n",
    "\n",
    "- X-y split.\n",
    "- Normalize (numerical)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0561a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
